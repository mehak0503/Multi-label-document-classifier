{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "spark = sparknlp.start() # for GPU training >> sparknlp.start(gpu = True) # for Spark 2.3 =>> sparknlp.start(spark23 = True)\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "from allComponents import Components\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.classification import LogisticRegression,LinearSVC\n",
    "from pyspark.ml.classification import RandomForestClassifier, OneVsRest\n",
    "from pyspark.ml.classification import NaiveBayes,MultilayerPerceptronClassifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.sql.functions import *\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "sc =SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    data = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('../neo_data.csv')\n",
    "    data1 = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('../PathCategorisation.csv')\n",
    "    df = data.join(data1, (data['nodes'] == data1['Document Name']))\n",
    "    oldColumns = ['Document Name','Category 1 (Mandatory)','Category 2 (Optional)','Category 3 (Optional)']\n",
    "    newColumns = ['DocumentName','Category1(Mandatory)','Category2(Optional)','Category3(Optional)']\n",
    "    df = reduce(lambda data, idx: data.withColumnRenamed(oldColumns[idx], newColumns[idx]), range(len(oldColumns)), df)\n",
    "    drop_list = ['Category3(Optional)']\n",
    "    result = df.select([column for column in df.columns if column not in drop_list])\n",
    "    #result.show(5)\n",
    "    return result\n",
    "\n",
    "df = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+--------------------+---+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
      "|               nodes|node_labels|          adj_labels|           adj_nodes|_c0|        DocumentName|            Location|Category1(Mandatory)|Category2(Optional)|                path|\n",
      "+--------------------+-----------+--------------------+--------------------+---+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
      "|Best in Care Aust...|       FILE|['FOLDER', 'CATEG...|   ['Data', 'Other']|563|Best in Care Aust...|C:\\Users\\classifi...|               Other|               null|['C:', 'Users', '...|\n",
      "|Bupa Seaforth - A...|       FILE|['FOLDER', 'CATEG...|   ['Data', 'Other']|564|Bupa Seaforth - A...|C:\\Users\\classifi...|               Other|               null|['C:', 'Users', '...|\n",
      "|PCA018_Guiding-Pr...|       FILE|['FOLDER', 'CATEG...|   ['Data', 'Other']|565|PCA018_Guiding-Pr...|C:\\Users\\classifi...|               Other|               null|['C:', 'Users', '...|\n",
      "|Sector performanc...|       FILE|['FOLDER', 'CATEG...|   ['Data', 'Other']|566|Sector performanc...|C:\\Users\\classifi...|               Other|               null|['C:', 'Users', '...|\n",
      "|La Trobe Literatu...|       FILE|['FOLDER', 'CATEG...|['AACQA (Australi...|259|La Trobe Literatu...|C:\\Users\\classifi...|              Report| Quality and Safety|['C:', 'Users', '...|\n",
      "+--------------------+-----------+--------------------+--------------------+---+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+-----------------+---+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
      "|               nodes|node_labels|          adj_labels|        adj_nodes|_c0|        DocumentName|            Location|Category1(Mandatory)|Category2(Optional)|                path|\n",
      "+--------------------+-----------+--------------------+-----------------+---+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
      "|Best in Care Aust...|       FILE|['FOLDER', 'CATEG...|['Data', 'Other']|563|Best in Care Aust...|C:\\Users\\classifi...|               Other|       NotSpecified|['C:', 'Users', '...|\n",
      "+--------------------+-----------+--------------------+-----------------+---+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.na.fill(\"NotSpecified\")#Fill empty\n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataframe):\n",
    "    (trainingData, testData) = dataframe.randomSplit([0.8, 0.2], seed = 100)\n",
    "    return trainingData, testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_test_data(trainingData,testData,outputCol):\n",
    "    @udf(\"long\")\n",
    "    def num_nonzeros(v):\n",
    "        return v.numNonzeros()\n",
    "    testData = testData.where(num_nonzeros(outputCol) != 0)\n",
    "    trainingData = trainingData.where(num_nonzeros(outputCol) != 0)\n",
    "    return trainingData,testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(dataframe,inputCol,outputCol):\n",
    "    evaluator = MulticlassClassificationEvaluator(predictionCol=outputCol)\n",
    "    print(\"MulticlassEvaluator score: \",evaluator.evaluate(dataframe))\n",
    "    df = dataframe.select(inputCol,outputCol,\"prediction\").toPandas()\n",
    "    print(classification_report(df.label, df.prediction))\n",
    "    print(accuracy_score(df.label, df.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(trainingData,testData):\n",
    "    lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0)\n",
    "    return lr.fit(trainingData).transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneRest(trainingData,testData):\n",
    "    lr = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True)\n",
    "    ovr = OneVsRest(classifier=lr)\n",
    "    return ovr.fit(trainingData).transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_classifier(trainingData,testData,inputCol,outputCol,bins):\n",
    "    rf = RandomForestClassifier(labelCol=outputCol, \\\n",
    "                            featuresCol=inputCol, \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = bins)\n",
    "\n",
    "    # Train model with Training Data\n",
    "    return rf.fit(trainingData).transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(trainingData,testData):\n",
    "    nb = NaiveBayes(smoothing=1)\n",
    "    return nb.fit(trainingData).transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline1(choice,outCol,*inputCol):\n",
    "    c = Components()\n",
    "    allStages1 = [c.getDocumentAssembler(inputCol[0],\"document\"),c.getTokenizer(\"document\",\"tokens\"),\\\n",
    "                  c.getNormalizer(\"tokens\",\"normalized\"),\\\n",
    "                c.getFinisher(\"normalized\",\"finished\")]\n",
    "    allStages2 = [c.getDocumentAssembler(inputCol[2],\"document1\"),c.getTokenizer(\"document1\",\"tokens1\"),\\\n",
    "                  c.getNormalizer(\"tokens1\",\"normalized1\"),\\\n",
    "                c.getFinisher(\"normalized1\",\"finished1\")]\n",
    "    allStages = allStages1+allStages2\n",
    "    if choice==0:#CountVectorizer\n",
    "        allStages.extend([c.getCountVectorizer(\"finished\",\"locFeature\"),\\\n",
    "                          c.getCountVectorizer(\"finished1\",\"adjFeature\"),\\\n",
    "                          c.getStringIndexer(inputCol[1],\"typeFeature\"),\\\n",
    "                          c.getVectorAssembler([\"locFeature\",\"typeFeature\",\"adjFeature\"],\"features\"),\\\n",
    "                          c.getStringIndexer(outCol,\"label\")])\n",
    "        return Pipeline(stages=allStages)\n",
    "    elif choice==1:#Tf-idf\n",
    "        allStages.extend([c.getTf(\"finished\",\"tf\"),c.getIdf(\"tf\",\"locFeature\"),\\\n",
    "                          c.getTf(\"finished1\",\"tf1\"),c.getIdf(\"tf1\",\"adjFeature\"),\\\n",
    "                          c.getStringIndexer(inputCol[1],\"typeFeature\"),\\\n",
    "                          c.getVectorAssembler([\"locFeature\",\"typeFeature\",\"adjFeature\"],\"features\"),\\\n",
    "                          c.getStringIndexer(outCol,\"label\")])\n",
    "        return Pipeline(stages=allStages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Label 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline 1: Using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputCol = \"nodes\"\n",
    "outputCol = \"Category1(Mandatory)\"\n",
    "pipeline = get_pipeline1(0,outputCol,inputCol,\"node_labels\",\"adj_nodes\")\n",
    "processed_df = pipeline.fit(df).transform(df)\n",
    "trainingData,testData = train_test_split(processed_df)\n",
    "bins = len(df.select(outputCol).distinct().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Logistic Regression\n",
      "\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96        22\n",
      "         1.0       1.00      1.00      1.00        18\n",
      "         2.0       1.00      1.00      1.00         9\n",
      "         3.0       1.00      1.00      1.00        10\n",
      "         4.0       1.00      1.00      1.00         9\n",
      "         5.0       1.00      1.00      1.00         7\n",
      "         6.0       1.00      1.00      1.00         4\n",
      "         7.0       1.00      1.00      1.00         3\n",
      "         8.0       0.67      1.00      0.80         2\n",
      "         9.0       1.00      1.00      1.00         4\n",
      "        10.0       1.00      1.00      1.00         3\n",
      "        11.0       1.00      1.00      1.00         3\n",
      "        12.0       1.00      1.00      1.00         3\n",
      "        15.0       1.00      1.00      1.00         2\n",
      "        16.0       1.00      1.00      1.00         2\n",
      "        17.0       1.00      1.00      1.00         1\n",
      "        18.0       1.00      1.00      1.00         1\n",
      "        20.0       1.00      1.00      1.00         2\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "        23.0       0.00      0.00      0.00         1\n",
      "        26.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.97       108\n",
      "   macro avg       0.84      0.86      0.85       108\n",
      "weighted avg       0.95      0.97      0.96       108\n",
      "\n",
      "0.9722222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "print(\"# Logistic Regression\\n\")\n",
    "get_classification_report(logistic_regression(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Random Forest\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      1.00      0.68        22\n",
      "         1.0       1.00      1.00      1.00        18\n",
      "         2.0       1.00      1.00      1.00         9\n",
      "         3.0       1.00      1.00      1.00        10\n",
      "         4.0       1.00      1.00      1.00         9\n",
      "         5.0       1.00      1.00      1.00         7\n",
      "         6.0       1.00      0.25      0.40         4\n",
      "         7.0       1.00      1.00      1.00         3\n",
      "         8.0       1.00      0.50      0.67         2\n",
      "         9.0       1.00      1.00      1.00         4\n",
      "        10.0       1.00      1.00      1.00         3\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "        12.0       0.00      0.00      0.00         3\n",
      "        15.0       0.00      0.00      0.00         2\n",
      "        16.0       0.00      0.00      0.00         2\n",
      "        17.0       0.00      0.00      0.00         1\n",
      "        18.0       0.00      0.00      0.00         1\n",
      "        20.0       0.00      0.00      0.00         2\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "        23.0       0.00      0.00      0.00         1\n",
      "        26.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.81       108\n",
      "   macro avg       0.50      0.46      0.46       108\n",
      "weighted avg       0.74      0.81      0.75       108\n",
      "\n",
      "0.8055555555555556\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "print(\"# Random Forest\")\n",
    "get_classification_report(random_forest_classifier(trainingData,testData,\"features\",\"label\",bins),\"features\",\"label\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Naive Bayes\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        22\n",
      "         1.0       1.00      1.00      1.00        18\n",
      "         2.0       0.90      1.00      0.95         9\n",
      "         3.0       1.00      1.00      1.00        10\n",
      "         4.0       1.00      1.00      1.00         9\n",
      "         5.0       1.00      1.00      1.00         7\n",
      "         6.0       1.00      1.00      1.00         4\n",
      "         7.0       1.00      1.00      1.00         3\n",
      "         8.0       0.67      1.00      0.80         2\n",
      "         9.0       1.00      1.00      1.00         4\n",
      "        10.0       1.00      1.00      1.00         3\n",
      "        11.0       1.00      1.00      1.00         3\n",
      "        12.0       1.00      1.00      1.00         3\n",
      "        15.0       1.00      1.00      1.00         2\n",
      "        16.0       1.00      1.00      1.00         2\n",
      "        17.0       1.00      1.00      1.00         1\n",
      "        18.0       1.00      1.00      1.00         1\n",
      "        20.0       1.00      1.00      1.00         2\n",
      "        22.0       1.00      1.00      1.00         1\n",
      "        23.0       0.00      0.00      0.00         1\n",
      "        26.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.98       108\n",
      "   macro avg       0.88      0.90      0.89       108\n",
      "weighted avg       0.97      0.98      0.97       108\n",
      "\n",
      "0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "print(\"# Naive Bayes\")\n",
    "get_classification_report(naive_bayes(trainingData,testData),\"features\",\"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Onevsrest\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        22\n",
      "         1.0       1.00      1.00      1.00        18\n",
      "         2.0       1.00      1.00      1.00         9\n",
      "         3.0       1.00      1.00      1.00        10\n",
      "         4.0       1.00      1.00      1.00         9\n",
      "         5.0       1.00      1.00      1.00         7\n",
      "         6.0       1.00      1.00      1.00         4\n",
      "         7.0       1.00      1.00      1.00         3\n",
      "         8.0       1.00      1.00      1.00         2\n",
      "         9.0       1.00      1.00      1.00         4\n",
      "        10.0       1.00      1.00      1.00         3\n",
      "        11.0       1.00      1.00      1.00         3\n",
      "        12.0       1.00      1.00      1.00         3\n",
      "        15.0       1.00      1.00      1.00         2\n",
      "        16.0       1.00      1.00      1.00         2\n",
      "        17.0       1.00      1.00      1.00         1\n",
      "        18.0       1.00      1.00      1.00         1\n",
      "        20.0       1.00      1.00      1.00         2\n",
      "        22.0       1.00      1.00      1.00         1\n",
      "        23.0       1.00      1.00      1.00         1\n",
      "        26.0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00       108\n",
      "   macro avg       1.00      1.00      1.00       108\n",
      "weighted avg       1.00      1.00      1.00       108\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#OneVsRest\n",
    "print(\"# Onevsrest\")\n",
    "get_classification_report(oneRest(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline 2: Using Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputCol = \"nodes\"\n",
    "outputCol = \"Category1(Mandatory)\"\n",
    "pipeline = get_pipeline1(1,outputCol,inputCol,\"node_labels\",\"adj_nodes\")\n",
    "processed_df = pipeline.fit(df).transform(df)\n",
    "trainingData,testData = train_test_split(processed_df)\n",
    "bins = len(df.select(outputCol).distinct().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Logistic Regression\n",
      "\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96        22\n",
      "         1.0       1.00      1.00      1.00        18\n",
      "         2.0       1.00      1.00      1.00         9\n",
      "         3.0       1.00      1.00      1.00        10\n",
      "         4.0       1.00      1.00      1.00         9\n",
      "         5.0       1.00      1.00      1.00         7\n",
      "         6.0       1.00      1.00      1.00         4\n",
      "         7.0       1.00      1.00      1.00         3\n",
      "         8.0       0.67      1.00      0.80         2\n",
      "         9.0       1.00      1.00      1.00         4\n",
      "        10.0       1.00      1.00      1.00         3\n",
      "        11.0       1.00      1.00      1.00         3\n",
      "        12.0       1.00      1.00      1.00         3\n",
      "        15.0       1.00      1.00      1.00         2\n",
      "        16.0       1.00      1.00      1.00         2\n",
      "        17.0       1.00      1.00      1.00         1\n",
      "        18.0       1.00      1.00      1.00         1\n",
      "        20.0       1.00      1.00      1.00         2\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "        23.0       0.00      0.00      0.00         1\n",
      "        26.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.97       108\n",
      "   macro avg       0.84      0.86      0.85       108\n",
      "weighted avg       0.95      0.97      0.96       108\n",
      "\n",
      "0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "print(\"# Logistic Regression\\n\")\n",
    "get_classification_report(logistic_regression(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Random Forest\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.20      1.00      0.34        22\n",
      "         1.0       0.00      0.00      0.00        18\n",
      "         2.0       0.00      0.00      0.00         9\n",
      "         3.0       0.00      0.00      0.00        10\n",
      "         4.0       0.00      0.00      0.00         9\n",
      "         5.0       0.00      0.00      0.00         7\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "         7.0       0.00      0.00      0.00         3\n",
      "         8.0       0.00      0.00      0.00         2\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.00      0.00      0.00         3\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "        12.0       0.00      0.00      0.00         3\n",
      "        15.0       0.00      0.00      0.00         2\n",
      "        16.0       0.00      0.00      0.00         2\n",
      "        17.0       0.00      0.00      0.00         1\n",
      "        18.0       0.00      0.00      0.00         1\n",
      "        20.0       0.00      0.00      0.00         2\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "        23.0       0.00      0.00      0.00         1\n",
      "        26.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.20       108\n",
      "   macro avg       0.01      0.05      0.02       108\n",
      "weighted avg       0.04      0.20      0.07       108\n",
      "\n",
      "0.2037037037037037\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "print(\"# Random Forest\")\n",
    "get_classification_report(random_forest_classifier(trainingData,testData,\"features\",\"label\",bins),\"features\",\"label\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Naive Bayes\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        22\n",
      "         1.0       1.00      1.00      1.00        18\n",
      "         2.0       0.90      1.00      0.95         9\n",
      "         3.0       1.00      1.00      1.00        10\n",
      "         4.0       1.00      1.00      1.00         9\n",
      "         5.0       1.00      1.00      1.00         7\n",
      "         6.0       1.00      1.00      1.00         4\n",
      "         7.0       1.00      1.00      1.00         3\n",
      "         8.0       0.67      1.00      0.80         2\n",
      "         9.0       1.00      1.00      1.00         4\n",
      "        10.0       1.00      1.00      1.00         3\n",
      "        11.0       1.00      1.00      1.00         3\n",
      "        12.0       1.00      1.00      1.00         3\n",
      "        15.0       1.00      1.00      1.00         2\n",
      "        16.0       1.00      1.00      1.00         2\n",
      "        17.0       1.00      1.00      1.00         1\n",
      "        18.0       1.00      1.00      1.00         1\n",
      "        20.0       1.00      1.00      1.00         2\n",
      "        22.0       1.00      1.00      1.00         1\n",
      "        23.0       0.00      0.00      0.00         1\n",
      "        26.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.98       108\n",
      "   macro avg       0.88      0.90      0.89       108\n",
      "weighted avg       0.97      0.98      0.97       108\n",
      "\n",
      "0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "print(\"# Naive Bayes\")\n",
    "get_classification_report(naive_bayes(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Onevsrest\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        22\n",
      "         1.0       1.00      1.00      1.00        18\n",
      "         2.0       1.00      1.00      1.00         9\n",
      "         3.0       1.00      1.00      1.00        10\n",
      "         4.0       1.00      1.00      1.00         9\n",
      "         5.0       1.00      1.00      1.00         7\n",
      "         6.0       1.00      1.00      1.00         4\n",
      "         7.0       1.00      1.00      1.00         3\n",
      "         8.0       1.00      1.00      1.00         2\n",
      "         9.0       1.00      1.00      1.00         4\n",
      "        10.0       1.00      1.00      1.00         3\n",
      "        11.0       1.00      1.00      1.00         3\n",
      "        12.0       1.00      1.00      1.00         3\n",
      "        15.0       1.00      1.00      1.00         2\n",
      "        16.0       1.00      1.00      1.00         2\n",
      "        17.0       1.00      1.00      1.00         1\n",
      "        18.0       1.00      1.00      1.00         1\n",
      "        20.0       1.00      1.00      1.00         2\n",
      "        22.0       1.00      1.00      1.00         1\n",
      "        23.0       1.00      1.00      1.00         1\n",
      "        26.0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00       108\n",
      "   macro avg       1.00      1.00      1.00       108\n",
      "weighted avg       1.00      1.00      1.00       108\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#OneVsRest\n",
    "print(\"# Onevsrest\")\n",
    "get_classification_report(oneRest(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
