{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "spark = sparknlp.start() # for GPU training >> sparknlp.start(gpu = True) # for Spark 2.3 =>> sparknlp.start(spark23 = True)\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "from allComponents import Components\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.classification import LogisticRegression,LinearSVC\n",
    "from pyspark.ml.classification import RandomForestClassifier, OneVsRest\n",
    "from pyspark.ml.classification import NaiveBayes,MultilayerPerceptronClassifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "sc =SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    data = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('../dataset.csv')\n",
    "    data1 = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('../Document Categorisation.csv')\n",
    "    df = data.join(data1, (data['filename'] == data1['Document Name']))\n",
    "    oldColumns = ['filename','filepath','filetype','filesize','filetext','translatedtext','Document Name','Location','Category 1 (Mandatory)','Category 2 (Optional)','Category 3 (Optional)']\n",
    "    newColumns = ['filename','filepath','filetype','filesize','filetext','translatedtext','DocumentName','Location','Category1(Mandatory)','Category2(Optional)','Category3(Optional)']\n",
    "    df = reduce(lambda data, idx: data.withColumnRenamed(oldColumns[idx], newColumns[idx]), range(len(oldColumns)), df)\n",
    "    drop_list = ['filename', 'filepath','filetext','Category3(Optional)']\n",
    "    result = df.select([column for column in df.columns if column not in drop_list])\n",
    "    #result.show(5)\n",
    "    return result\n",
    "\n",
    "df = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "|filetype|filesize|      translatedtext|        DocumentName|            Location|Category1(Mandatory)|Category2(Optional)|\n",
      "+--------+--------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "|     pdf|  110537|Sector performanc...|Sector performanc...|C:\\Users\\classifi...|               Other|       NotSpecified|\n",
      "+--------+--------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.na.fill(\"NotSpecified\")#Fill empty\n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline1(choice,inputCol,outCol):\n",
    "    c = Components()\n",
    "    allStages = [c.getDocumentAssembler(inputCol,\"document\"),c.getTokenizer(\"document\",\"tokens\"), c.getNormalizer(\"tokens\",\"normalized\"),\\\n",
    "                        c.getStopWordCleaner(\"normalized\",\"cleaned\"), c.getStemmer(\"cleaned\",\"stemmed\"),\\\n",
    "                        c.getFinisher(\"stemmed\",\"finished\")]\n",
    "    if choice==0:#CountVectorizer\n",
    "        allStages.extend([c.getCountVectorizer(\"finished\",\"features\"),c.getStringIndexer(outCol,\"label\")])\n",
    "        return Pipeline(stages=allStages)\n",
    "    elif choice==1:#Tf-idf\n",
    "        allStages.extend([c.getTf(\"finished\",\"tf\"),c.getIdf(\"tf\",\"features\"),c.getStringIndexer(outCol,\"label\")])\n",
    "        return Pipeline(stages=allStages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline2(choice,inputCol,outCol):\n",
    "    c = Components()\n",
    "    allStages = [c.getDocumentAssembler(inputCol,\"document\"),c.getTokenizer(\"document\",\"tokens\"), \n",
    "                 c.getNormalizer(\"tokens\",\"normalized\"),c.getStopWordCleaner(\"normalized\",\"cleaned\"), \n",
    "                 c.getStemmer(\"cleaned\",\"stemmed\")]\n",
    "    if choice==0:#Glove Embeddings\n",
    "        allStages.extend([c.getGloveEmbeddings([\"document\",\"stemmed\"],\"embeddings\"),\\\n",
    "                          c.getEmbeddingSentence([\"document\", \"embeddings\"],\"sentence_embeddings\"),\\\n",
    "                          c.getEmbeddingFinisher(\"sentence_embeddings\",\"finished_sentence_embeddings\"),\\\n",
    "                          c.getExplodeVectors(\"finished_sentence_embeddings\",\"features\"),\\\n",
    "                          c.getStringIndexer(outCol,\"label\")])\n",
    "        print(allStages)\n",
    "        return Pipeline(stages=allStages)\n",
    "    elif choice==1:#BERT Embeddings\n",
    "        allStages.extend([c.getBERTEmbeddings([\"document\",\"stemmed\"],\"embeddings\"),\\\n",
    "                          c.getEmbeddingSentence([\"document\", \"embeddings\"],\"sentence_embeddings\"),\\\n",
    "                          c.getEmbeddingFinisher(\"sentence_embeddings\",\"finished_sentence_embeddings\"),\\\n",
    "                          c.getExplodeVectors(\"finished_sentence_embeddings\",\"features\"),\\\n",
    "                          c.getStringIndexer(outCol,\"label\")])\n",
    "        return Pipeline(stages=allStages)    \n",
    "    elif choice==2:#ELMO Embeddings\n",
    "        allStages.extend([c.getELMOEmbeddings([\"document\",\"stemmed\"],\"embeddings\"),\\\n",
    "                          c.getEmbeddingSentence([\"document\", \"embeddings\"],\"sentence_embeddings\"),\\\n",
    "                          c.getEmbeddingFinisher(\"sentence_embeddings\",\"finished_sentence_embeddings\"),\\\n",
    "                          c.getExplodeVectors(\"finished_sentence_embeddings\",\"features\"),\\\n",
    "                          c.getStringIndexer(outCol,\"label\")])\n",
    "        return Pipeline(stages=allStages)\n",
    "    elif choice==3:#USE Embeddings\n",
    "        allStages = [c.getDocumentAssembler(inputCol,\"document\"),\\\n",
    "                         c.getUSEEmbeddings(\"document\",\"embeddings\"),\\\n",
    "                          c.getEmbeddingFinisher(\"embeddings\",\"finished_sentence_embeddings\"),\\\n",
    "                          c.getExplodeVectors(\"finished_sentence_embeddings\",\"features\"),\\\n",
    "                          c.getStringIndexer(outCol,\"label\")]\n",
    "        return Pipeline(stages=allStages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataframe):\n",
    "    (trainingData, testData) = dataframe.randomSplit([0.8, 0.2], seed = 100)\n",
    "    return trainingData, testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_test_data(trainingData,testData,outputCol):\n",
    "    @udf(\"long\")\n",
    "    def num_nonzeros(v):\n",
    "        return v.numNonzeros()\n",
    "    testData = testData.where(num_nonzeros(outputCol) != 0)\n",
    "    trainingData = trainingData.where(num_nonzeros(outputCol) != 0)\n",
    "    return trainingData,testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(dataframe,inputCol,outputCol):\n",
    "    evaluator = MulticlassClassificationEvaluator(predictionCol=outputCol)\n",
    "    print(\"MulticlassEvaluator score: \",evaluator.evaluate(dataframe))\n",
    "    df = dataframe.select(inputCol,outputCol,\"prediction\").toPandas()\n",
    "    print(classification_report(df.label, df.prediction))\n",
    "    print(accuracy_score(df.label, df.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(trainingData,testData):\n",
    "    lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0)\n",
    "    return lr.fit(trainingData).transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(trainingData,testData,inputCol,outputCol,bins):\n",
    "    dt = DecisionTreeClassifier(featuresCol = inputCol, labelCol = outputCol, maxDepth = 3,maxBins = bins)\n",
    "    return dt.fit(trainingData).transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneRest(trainingData,testData):\n",
    "    lr = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True)\n",
    "    ovr = OneVsRest(classifier=lr)\n",
    "    return ovr.fit(trainingData).transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_classifier(trainingData,testData,inputCol,outputCol,bins):\n",
    "    rf = RandomForestClassifier(labelCol=outputCol, \\\n",
    "                            featuresCol=inputCol, \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = bins)\n",
    "\n",
    "    # Train model with Training Data\n",
    "    return rf.fit(trainingData).transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(trainingData,testData):\n",
    "    nb = NaiveBayes(smoothing=1)\n",
    "    return nb.fit(trainingData).transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# For Label 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline 1. Using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputCol = \"translatedtext\"\n",
    "outputCol = \"Category1(Mandatory)\"\n",
    "pipeline = get_pipeline1(0,inputCol,outputCol)\n",
    "processed_df = pipeline.fit(df).transform(df)\n",
    "trainingData,testData = train_test_split(processed_df)\n",
    "bins = len(df.select(outputCol).distinct().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Logistic Regression\n",
      "\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      1.00      0.65        22\n",
      "         1.0       1.00      0.79      0.88        14\n",
      "         2.0       0.50      0.43      0.46         7\n",
      "         3.0       1.00      0.64      0.78        11\n",
      "         4.0       0.86      0.86      0.86         7\n",
      "         5.0       0.86      0.86      0.86         7\n",
      "         6.0       0.50      0.12      0.20         8\n",
      "         7.0       1.00      1.00      1.00         1\n",
      "         8.0       1.00      1.00      1.00         4\n",
      "         9.0       1.00      1.00      1.00         6\n",
      "        10.0       1.00      0.33      0.50         3\n",
      "        11.0       1.00      1.00      1.00         5\n",
      "        12.0       1.00      0.40      0.57         5\n",
      "        13.0       0.00      0.00      0.00         3\n",
      "        14.0       1.00      0.50      0.67         2\n",
      "        16.0       1.00      1.00      1.00         2\n",
      "        20.0       1.00      1.00      1.00         1\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.72       109\n",
      "   macro avg       0.79      0.66      0.69       109\n",
      "weighted avg       0.77      0.72      0.70       109\n",
      "\n",
      "0.7247706422018348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "print(\"# Logistic Regression\\n\")\n",
    "get_classification_report(logistic_regression(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Decision Tree\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      1.00      0.44        22\n",
      "         1.0       1.00      0.57      0.73        14\n",
      "         2.0       0.00      0.00      0.00         7\n",
      "         3.0       0.00      0.00      0.00        11\n",
      "         4.0       0.86      0.86      0.86         7\n",
      "         5.0       0.78      1.00      0.88         7\n",
      "         6.0       0.00      0.00      0.00         8\n",
      "         7.0       1.00      1.00      1.00         1\n",
      "         8.0       0.00      0.00      0.00         4\n",
      "         9.0       0.00      0.00      0.00         6\n",
      "        10.0       0.00      0.00      0.00         3\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "        12.0       0.00      0.00      0.00         5\n",
      "        13.0       0.00      0.00      0.00         3\n",
      "        14.0       0.00      0.00      0.00         2\n",
      "        16.0       0.00      0.00      0.00         2\n",
      "        20.0       0.00      0.00      0.00         1\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.40       109\n",
      "   macro avg       0.22      0.25      0.22       109\n",
      "weighted avg       0.30      0.40      0.30       109\n",
      "\n",
      "0.4036697247706422\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "print(\"# Decision Tree\")\n",
    "get_classification_report(decision_tree(trainingData,testData,\"features\",\"label\",bins),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Random Forest\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.35      1.00      0.52        22\n",
      "         1.0       0.92      0.79      0.85        14\n",
      "         2.0       0.10      0.14      0.12         7\n",
      "         3.0       1.00      0.45      0.62        11\n",
      "         4.0       1.00      1.00      1.00         7\n",
      "         5.0       0.00      0.00      0.00         7\n",
      "         6.0       0.00      0.00      0.00         8\n",
      "         7.0       1.00      1.00      1.00         1\n",
      "         8.0       0.80      1.00      0.89         4\n",
      "         9.0       0.00      0.00      0.00         6\n",
      "        10.0       0.00      0.00      0.00         3\n",
      "        11.0       1.00      1.00      1.00         5\n",
      "        12.0       0.00      0.00      0.00         5\n",
      "        13.0       0.00      0.00      0.00         3\n",
      "        14.0       1.00      0.50      0.67         2\n",
      "        16.0       0.00      0.00      0.00         2\n",
      "        20.0       0.00      0.00      0.00         1\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.52       109\n",
      "   macro avg       0.40      0.38      0.37       109\n",
      "weighted avg       0.46      0.52      0.45       109\n",
      "\n",
      "0.5229357798165137\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "print(\"# Random Forest\")\n",
    "get_classification_report(random_forest_classifier(trainingData,testData,\"features\",\"label\",bins),\"features\",\"label\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Naive Bayes\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.86      0.84        22\n",
      "         1.0       1.00      0.86      0.92        14\n",
      "         2.0       0.42      0.71      0.53         7\n",
      "         3.0       0.62      0.45      0.53        11\n",
      "         4.0       0.64      1.00      0.78         7\n",
      "         5.0       0.71      0.71      0.71         7\n",
      "         6.0       0.33      0.25      0.29         8\n",
      "         7.0       0.50      1.00      0.67         1\n",
      "         8.0       0.57      1.00      0.73         4\n",
      "         9.0       0.86      1.00      0.92         6\n",
      "        10.0       0.50      0.33      0.40         3\n",
      "        11.0       1.00      1.00      1.00         5\n",
      "        12.0       0.67      0.40      0.50         5\n",
      "        13.0       0.00      0.00      0.00         3\n",
      "        14.0       1.00      0.50      0.67         2\n",
      "        16.0       1.00      0.50      0.67         2\n",
      "        18.0       0.00      0.00      0.00         0\n",
      "        20.0       1.00      1.00      1.00         1\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.71       109\n",
      "   macro avg       0.61      0.61      0.59       109\n",
      "weighted avg       0.71      0.71      0.69       109\n",
      "\n",
      "0.7064220183486238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "print(\"# Naive Bayes\")\n",
    "get_classification_report(naive_bayes(trainingData,testData),\"features\",\"label\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Onevsrest\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      1.00      0.77        22\n",
      "         1.0       1.00      0.71      0.83        14\n",
      "         2.0       0.80      0.57      0.67         7\n",
      "         3.0       0.89      0.73      0.80        11\n",
      "         4.0       0.75      0.86      0.80         7\n",
      "         5.0       0.64      1.00      0.78         7\n",
      "         6.0       0.33      0.12      0.18         8\n",
      "         7.0       1.00      1.00      1.00         1\n",
      "         8.0       0.80      1.00      0.89         4\n",
      "         9.0       1.00      1.00      1.00         6\n",
      "        10.0       1.00      0.33      0.50         3\n",
      "        11.0       1.00      1.00      1.00         5\n",
      "        12.0       0.67      0.80      0.73         5\n",
      "        13.0       0.00      0.00      0.00         3\n",
      "        14.0       1.00      0.50      0.67         2\n",
      "        16.0       1.00      1.00      1.00         2\n",
      "        20.0       1.00      1.00      1.00         1\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.76       109\n",
      "   macro avg       0.75      0.70      0.70       109\n",
      "weighted avg       0.75      0.76      0.73       109\n",
      "\n",
      "0.7614678899082569\n"
     ]
    }
   ],
   "source": [
    "#OneVsRest\n",
    "print(\"# Onevsrest\")\n",
    "get_classification_report(oneRest(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline 2: Using TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputCol = \"translatedtext\"\n",
    "outputCol = \"Category1(Mandatory)\"\n",
    "pipeline = get_pipeline1(0,inputCol,outputCol)\n",
    "processed_df = pipeline.fit(df).transform(df)\n",
    "trainingData,testData = train_test_split(processed_df)\n",
    "bins = len(df.select(outputCol).distinct().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Logistic Regression\n",
      "\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      1.00      0.65        22\n",
      "         1.0       1.00      0.79      0.88        14\n",
      "         2.0       0.50      0.43      0.46         7\n",
      "         3.0       1.00      0.64      0.78        11\n",
      "         4.0       0.86      0.86      0.86         7\n",
      "         5.0       0.86      0.86      0.86         7\n",
      "         6.0       0.50      0.12      0.20         8\n",
      "         7.0       1.00      1.00      1.00         1\n",
      "         8.0       1.00      1.00      1.00         4\n",
      "         9.0       1.00      1.00      1.00         6\n",
      "        10.0       1.00      0.33      0.50         3\n",
      "        11.0       1.00      1.00      1.00         5\n",
      "        12.0       1.00      0.40      0.57         5\n",
      "        13.0       0.00      0.00      0.00         3\n",
      "        14.0       1.00      0.50      0.67         2\n",
      "        16.0       1.00      1.00      1.00         2\n",
      "        20.0       1.00      1.00      1.00         1\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.72       109\n",
      "   macro avg       0.79      0.66      0.69       109\n",
      "weighted avg       0.77      0.72      0.70       109\n",
      "\n",
      "0.7247706422018348\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "print(\"# Logistic Regression\\n\")\n",
    "get_classification_report(logistic_regression(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Random Forest\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.35      1.00      0.52        22\n",
      "         1.0       0.83      0.71      0.77        14\n",
      "         2.0       0.17      0.14      0.15         7\n",
      "         3.0       1.00      0.45      0.62        11\n",
      "         4.0       1.00      0.71      0.83         7\n",
      "         5.0       1.00      0.57      0.73         7\n",
      "         6.0       1.00      0.12      0.22         8\n",
      "         7.0       1.00      1.00      1.00         1\n",
      "         8.0       0.67      1.00      0.80         4\n",
      "         9.0       1.00      0.17      0.29         6\n",
      "        10.0       0.00      0.00      0.00         3\n",
      "        11.0       1.00      1.00      1.00         5\n",
      "        12.0       0.00      0.00      0.00         5\n",
      "        13.0       0.00      0.00      0.00         3\n",
      "        14.0       1.00      0.50      0.67         2\n",
      "        16.0       0.00      0.00      0.00         2\n",
      "        20.0       0.00      0.00      0.00         1\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.55       109\n",
      "   macro avg       0.56      0.41      0.42       109\n",
      "weighted avg       0.65      0.55      0.51       109\n",
      "\n",
      "0.5504587155963303\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "print(\"# Random Forest\")\n",
    "get_classification_report(random_forest_classifier(trainingData,testData,\"features\",\"label\",bins),\"features\",\"label\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Naive Bayes\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.86      0.84        22\n",
      "         1.0       1.00      0.86      0.92        14\n",
      "         2.0       0.42      0.71      0.53         7\n",
      "         3.0       0.62      0.45      0.53        11\n",
      "         4.0       0.64      1.00      0.78         7\n",
      "         5.0       0.71      0.71      0.71         7\n",
      "         6.0       0.33      0.25      0.29         8\n",
      "         7.0       0.50      1.00      0.67         1\n",
      "         8.0       0.57      1.00      0.73         4\n",
      "         9.0       0.86      1.00      0.92         6\n",
      "        10.0       0.50      0.33      0.40         3\n",
      "        11.0       1.00      1.00      1.00         5\n",
      "        12.0       0.67      0.40      0.50         5\n",
      "        13.0       0.00      0.00      0.00         3\n",
      "        14.0       1.00      0.50      0.67         2\n",
      "        16.0       1.00      0.50      0.67         2\n",
      "        18.0       0.00      0.00      0.00         0\n",
      "        20.0       1.00      1.00      1.00         1\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.71       109\n",
      "   macro avg       0.61      0.61      0.59       109\n",
      "weighted avg       0.71      0.71      0.69       109\n",
      "\n",
      "0.7064220183486238\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "print(\"# Naive Bayes\")\n",
    "get_classification_report(naive_bayes(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Onevsrest\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      1.00      0.77        22\n",
      "         1.0       1.00      0.71      0.83        14\n",
      "         2.0       0.80      0.57      0.67         7\n",
      "         3.0       0.89      0.73      0.80        11\n",
      "         4.0       0.75      0.86      0.80         7\n",
      "         5.0       0.64      1.00      0.78         7\n",
      "         6.0       0.33      0.12      0.18         8\n",
      "         7.0       1.00      1.00      1.00         1\n",
      "         8.0       0.80      1.00      0.89         4\n",
      "         9.0       1.00      1.00      1.00         6\n",
      "        10.0       1.00      0.33      0.50         3\n",
      "        11.0       1.00      1.00      1.00         5\n",
      "        12.0       0.67      0.80      0.73         5\n",
      "        13.0       0.00      0.00      0.00         3\n",
      "        14.0       1.00      0.50      0.67         2\n",
      "        16.0       1.00      1.00      1.00         2\n",
      "        20.0       1.00      1.00      1.00         1\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.76       109\n",
      "   macro avg       0.75      0.70      0.70       109\n",
      "weighted avg       0.75      0.76      0.73       109\n",
      "\n",
      "0.7614678899082569\n"
     ]
    }
   ],
   "source": [
    "#OneVsRest\n",
    "print(\"# Onevsrest\")\n",
    "get_classification_report(oneRest(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline 3: Using Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n",
      "[DocumentAssembler_654a27c1896a, Tokenizer_f381b3e0f9c7, Normalizer_0b4fed457aca, StopWordsCleaner_ab41a111d871, Stemmer_f6ba936ced1e, WORD_EMBEDDINGS_MODEL_48cffc8b9a76, SentenceEmbeddings_7b2f3747b873, EmbeddingsFinisher_fb5ba8138f59, SQLTransformer_7f3e1b63cd34, StringIndexer_e5e656271516]\n"
     ]
    }
   ],
   "source": [
    "inputCol = \"translatedtext\"\n",
    "outputCol = \"Category1(Mandatory)\"\n",
    "pipeline = get_pipeline2(0,inputCol,outputCol)\n",
    "processed_df = pipeline.fit(df).transform(df)\n",
    "trainingData,testData = train_test_split(processed_df)\n",
    "trainingData,testData = process_train_test_data(trainingData,testData,\"features\")\n",
    "bins = len(df.select(outputCol).distinct().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Logistic Regression\n",
      "\n",
      "MulticlassEvaluator score:  0.9999999999999998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.31      0.88      0.45        17\n",
      "         1.0       0.48      0.83      0.61        12\n",
      "         2.0       0.50      0.62      0.56         8\n",
      "         3.0       0.38      0.75      0.50         4\n",
      "         4.0       1.00      0.62      0.77         8\n",
      "         5.0       0.86      0.75      0.80         8\n",
      "         6.0       0.00      0.00      0.00         6\n",
      "         7.0       0.00      0.00      0.00         4\n",
      "         8.0       1.00      0.33      0.50         3\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.00      0.00      0.00         4\n",
      "        11.0       1.00      0.17      0.29         6\n",
      "        12.0       0.00      0.00      0.00         1\n",
      "        13.0       0.00      0.00      0.00         2\n",
      "        14.0       0.00      0.00      0.00         2\n",
      "        15.0       0.00      0.00      0.00         1\n",
      "        16.0       0.00      0.00      0.00         2\n",
      "        17.0       0.00      0.00      0.00         2\n",
      "        19.0       0.00      0.00      0.00         3\n",
      "        20.0       0.00      0.00      0.00         2\n",
      "        21.0       0.00      0.00      0.00         1\n",
      "        23.0       0.00      0.00      0.00         1\n",
      "        26.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.45       102\n",
      "   macro avg       0.24      0.22      0.19       102\n",
      "weighted avg       0.39      0.45      0.36       102\n",
      "\n",
      "0.45098039215686275\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "print(\"# Logistic Regression\\n\")\n",
    "get_classification_report(logistic_regression(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Random Forest\n",
      "MulticlassEvaluator score:  0.9999999999999998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.35      0.94      0.51        17\n",
      "         1.0       0.43      0.83      0.57        12\n",
      "         2.0       0.36      0.62      0.45         8\n",
      "         3.0       0.75      0.75      0.75         4\n",
      "         4.0       1.00      0.62      0.77         8\n",
      "         5.0       1.00      0.62      0.77         8\n",
      "         6.0       0.00      0.00      0.00         6\n",
      "         7.0       1.00      0.25      0.40         4\n",
      "         8.0       0.00      0.00      0.00         3\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.00      0.00      0.00         4\n",
      "        11.0       1.00      0.67      0.80         6\n",
      "        12.0       0.00      0.00      0.00         1\n",
      "        13.0       0.00      0.00      0.00         2\n",
      "        14.0       0.00      0.00      0.00         2\n",
      "        15.0       0.00      0.00      0.00         1\n",
      "        16.0       0.00      0.00      0.00         2\n",
      "        17.0       0.00      0.00      0.00         2\n",
      "        19.0       0.00      0.00      0.00         3\n",
      "        20.0       0.00      0.00      0.00         2\n",
      "        21.0       0.00      0.00      0.00         1\n",
      "        23.0       0.00      0.00      0.00         1\n",
      "        26.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.48       102\n",
      "   macro avg       0.26      0.23      0.22       102\n",
      "weighted avg       0.42      0.48      0.40       102\n",
      "\n",
      "0.4803921568627451\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "print(\"# Random Forest\")\n",
    "get_classification_report(random_forest_classifier(trainingData,testData,\"features\",\"label\",bins),\"features\",\"label\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Onevsrest\n",
      "MulticlassEvaluator score:  0.9999999999999998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.88      0.75        17\n",
      "         1.0       0.65      0.92      0.76        12\n",
      "         2.0       0.60      0.38      0.46         8\n",
      "         3.0       0.43      0.75      0.55         4\n",
      "         4.0       0.83      0.62      0.71         8\n",
      "         5.0       0.83      0.62      0.71         8\n",
      "         6.0       0.00      0.00      0.00         6\n",
      "         7.0       1.00      0.75      0.86         4\n",
      "         8.0       0.33      0.67      0.44         3\n",
      "         9.0       0.67      1.00      0.80         4\n",
      "        10.0       0.33      0.50      0.40         4\n",
      "        11.0       1.00      0.67      0.80         6\n",
      "        12.0       1.00      1.00      1.00         1\n",
      "        13.0       0.00      0.00      0.00         2\n",
      "        14.0       1.00      0.50      0.67         2\n",
      "        15.0       0.00      0.00      0.00         1\n",
      "        16.0       1.00      0.50      0.67         2\n",
      "        17.0       0.00      0.00      0.00         2\n",
      "        19.0       1.00      0.33      0.50         3\n",
      "        20.0       1.00      1.00      1.00         2\n",
      "        21.0       0.00      0.00      0.00         1\n",
      "        23.0       1.00      1.00      1.00         1\n",
      "        26.0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.64       102\n",
      "   macro avg       0.62      0.57      0.57       102\n",
      "weighted avg       0.64      0.64      0.61       102\n",
      "\n",
      "0.6372549019607843\n"
     ]
    }
   ],
   "source": [
    "#OneVsRest\n",
    "print(\"# Onevsrest\")\n",
    "get_classification_report(oneRest(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline 4: Using BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 389.2 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "inputCol = \"translatedtext\"\n",
    "outputCol = \"Category1(Mandatory)\"\n",
    "pipeline = get_pipeline2(1,inputCol,outputCol)\n",
    "processed_df = pipeline.fit(df).transform(df)\n",
    "trainingData,testData = train_test_split(processed_df)\n",
    "trainingData,testData = process_train_test_data(trainingData,testData,\"features\")\n",
    "bins = len(df.select(outputCol).distinct().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Logistic Regression\n",
      "\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.95      0.78        22\n",
      "         1.0       0.70      0.88      0.78        16\n",
      "         2.0       0.35      0.88      0.50         8\n",
      "         3.0       0.54      0.78      0.64         9\n",
      "         4.0       0.43      0.38      0.40         8\n",
      "         5.0       0.75      0.43      0.55         7\n",
      "         6.0       1.00      0.17      0.29         6\n",
      "         7.0       1.00      0.50      0.67         2\n",
      "         8.0       0.50      0.33      0.40         3\n",
      "         9.0       1.00      1.00      1.00         2\n",
      "        10.0       0.50      0.33      0.40         3\n",
      "        11.0       1.00      0.67      0.80         3\n",
      "        12.0       0.00      0.00      0.00         3\n",
      "        13.0       0.00      0.00      0.00         3\n",
      "        14.0       0.00      0.00      0.00         2\n",
      "        15.0       0.00      0.00      0.00         2\n",
      "        17.0       0.00      0.00      0.00         1\n",
      "        18.0       0.00      0.00      0.00         2\n",
      "        19.0       0.00      0.00      0.00         1\n",
      "        20.0       1.00      1.00      1.00         1\n",
      "        21.0       0.00      0.00      0.00         1\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "        24.0       0.00      0.00      0.00         1\n",
      "        25.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.59       108\n",
      "   macro avg       0.39      0.35      0.34       108\n",
      "weighted avg       0.55      0.59      0.53       108\n",
      "\n",
      "0.5925925925925926\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "print(\"# Logistic Regression\\n\")\n",
    "get_classification_report(logistic_regression(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Random Forest\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      1.00      0.50        22\n",
      "         1.0       0.75      0.75      0.75        16\n",
      "         2.0       0.12      0.25      0.16         8\n",
      "         3.0       1.00      0.56      0.71         9\n",
      "         4.0       0.50      0.25      0.33         8\n",
      "         5.0       0.00      0.00      0.00         7\n",
      "         6.0       0.00      0.00      0.00         6\n",
      "         7.0       0.00      0.00      0.00         2\n",
      "         8.0       0.00      0.00      0.00         3\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.00      0.00      0.00         3\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "        12.0       0.00      0.00      0.00         3\n",
      "        13.0       0.00      0.00      0.00         3\n",
      "        14.0       0.00      0.00      0.00         2\n",
      "        15.0       0.00      0.00      0.00         2\n",
      "        17.0       0.00      0.00      0.00         1\n",
      "        18.0       0.00      0.00      0.00         2\n",
      "        19.0       0.00      0.00      0.00         1\n",
      "        20.0       0.00      0.00      0.00         1\n",
      "        21.0       0.00      0.00      0.00         1\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "        24.0       0.00      0.00      0.00         1\n",
      "        25.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.40       108\n",
      "   macro avg       0.11      0.12      0.10       108\n",
      "weighted avg       0.31      0.40      0.31       108\n",
      "\n",
      "0.39814814814814814\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "print(\"# Random Forest\")\n",
    "get_classification_report(random_forest_classifier(trainingData,testData,\"features\",\"label\",bins),\"features\",\"label\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Onevsrest\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.86      0.75        22\n",
      "         1.0       0.81      0.81      0.81        16\n",
      "         2.0       0.37      0.88      0.52         8\n",
      "         3.0       0.67      0.89      0.76         9\n",
      "         4.0       0.60      0.38      0.46         8\n",
      "         5.0       0.83      0.71      0.77         7\n",
      "         6.0       0.40      0.33      0.36         6\n",
      "         7.0       1.00      1.00      1.00         2\n",
      "         8.0       0.50      0.33      0.40         3\n",
      "         9.0       1.00      1.00      1.00         2\n",
      "        10.0       0.50      0.33      0.40         3\n",
      "        11.0       1.00      0.67      0.80         3\n",
      "        12.0       0.00      0.00      0.00         3\n",
      "        13.0       0.00      0.00      0.00         3\n",
      "        14.0       0.00      0.00      0.00         2\n",
      "        15.0       0.00      0.00      0.00         2\n",
      "        17.0       0.00      0.00      0.00         1\n",
      "        18.0       0.00      0.00      0.00         2\n",
      "        19.0       0.00      0.00      0.00         1\n",
      "        20.0       1.00      1.00      1.00         1\n",
      "        21.0       0.00      0.00      0.00         1\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "        24.0       0.00      0.00      0.00         1\n",
      "        25.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.61       108\n",
      "   macro avg       0.39      0.38      0.38       108\n",
      "weighted avg       0.56      0.61      0.57       108\n",
      "\n",
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "#OneVsRest\n",
    "print(\"# Onevsrest\")\n",
    "get_classification_report(oneRest(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline 5: Using ELMO Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elmo download started this may take some time.\n",
      "Approximate size to download 334.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "inputCol = \"translatedtext\"\n",
    "outputCol = \"Category1(Mandatory)\"\n",
    "pipeline = get_pipeline2(2,inputCol,outputCol)\n",
    "processed_df = pipeline.fit(df).transform(df)\n",
    "trainingData,testData = train_test_split(processed_df)\n",
    "trainingData,testData = process_train_test_data(trainingData,testData,\"features\")\n",
    "bins = len(df.select(outputCol).distinct().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Logistic Regression\n",
      "\n",
      "MulticlassEvaluator score:  1.0000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.91      0.86        23\n",
      "         1.0       0.72      0.87      0.79        15\n",
      "         2.0       0.29      0.82      0.43        11\n",
      "         3.0       0.83      0.71      0.77         7\n",
      "         4.0       1.00      0.78      0.88         9\n",
      "         5.0       0.50      0.75      0.60         4\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "         7.0       1.00      0.33      0.50         3\n",
      "         8.0       0.00      0.00      0.00         2\n",
      "         9.0       0.60      0.75      0.67         4\n",
      "        10.0       1.00      0.25      0.40         4\n",
      "        11.0       1.00      1.00      1.00         5\n",
      "        12.0       0.00      0.00      0.00         3\n",
      "        13.0       0.00      0.00      0.00         4\n",
      "        14.0       0.00      0.00      0.00         1\n",
      "        15.0       0.00      0.00      0.00         2\n",
      "        16.0       0.00      0.00      0.00         1\n",
      "        18.0       0.00      0.00      0.00         1\n",
      "        19.0       0.00      0.00      0.00         1\n",
      "        21.0       0.00      0.00      0.00         1\n",
      "        22.0       0.00      0.00      0.00         2\n",
      "        26.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.63       108\n",
      "   macro avg       0.35      0.33      0.31       108\n",
      "weighted avg       0.59      0.63      0.58       108\n",
      "\n",
      "0.6296296296296297\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "print(\"# Logistic Regression\\n\")\n",
    "get_classification_report(logistic_regression(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Random Forest\n",
      "MulticlassEvaluator score:  1.0000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      1.00      0.74        23\n",
      "         1.0       0.59      0.87      0.70        15\n",
      "         2.0       0.25      0.55      0.34        11\n",
      "         3.0       0.44      0.57      0.50         7\n",
      "         4.0       1.00      0.67      0.80         9\n",
      "         5.0       1.00      0.50      0.67         4\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "         7.0       1.00      0.33      0.50         3\n",
      "         8.0       0.00      0.00      0.00         2\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.00      0.00      0.00         4\n",
      "        11.0       1.00      1.00      1.00         5\n",
      "        12.0       0.00      0.00      0.00         3\n",
      "        13.0       0.00      0.00      0.00         4\n",
      "        14.0       0.00      0.00      0.00         1\n",
      "        15.0       0.00      0.00      0.00         2\n",
      "        16.0       0.00      0.00      0.00         1\n",
      "        18.0       0.00      0.00      0.00         1\n",
      "        19.0       0.00      0.00      0.00         1\n",
      "        21.0       0.00      0.00      0.00         1\n",
      "        22.0       0.00      0.00      0.00         2\n",
      "        26.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.56       108\n",
      "   macro avg       0.27      0.25      0.24       108\n",
      "weighted avg       0.46      0.56      0.47       108\n",
      "\n",
      "0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "print(\"# Random Forest\")\n",
    "get_classification_report(random_forest_classifier(trainingData,testData,\"features\",\"label\",bins),\"features\",\"label\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Onevsrest\n",
      "MulticlassEvaluator score:  1.0000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.91      0.93        23\n",
      "         1.0       0.78      0.93      0.85        15\n",
      "         2.0       0.62      0.73      0.67        11\n",
      "         3.0       0.67      0.57      0.62         7\n",
      "         4.0       0.89      0.89      0.89         9\n",
      "         5.0       0.75      0.75      0.75         4\n",
      "         6.0       0.17      0.25      0.20         4\n",
      "         7.0       1.00      0.33      0.50         3\n",
      "         8.0       0.50      1.00      0.67         2\n",
      "         9.0       1.00      1.00      1.00         4\n",
      "        10.0       0.33      0.25      0.29         4\n",
      "        11.0       1.00      1.00      1.00         5\n",
      "        12.0       0.67      0.67      0.67         3\n",
      "        13.0       0.00      0.00      0.00         4\n",
      "        14.0       0.50      1.00      0.67         1\n",
      "        15.0       1.00      1.00      1.00         2\n",
      "        16.0       1.00      1.00      1.00         1\n",
      "        18.0       0.50      1.00      0.67         1\n",
      "        19.0       1.00      1.00      1.00         1\n",
      "        21.0       0.00      0.00      0.00         1\n",
      "        22.0       0.00      0.00      0.00         2\n",
      "        26.0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.75       108\n",
      "   macro avg       0.65      0.69      0.65       108\n",
      "weighted avg       0.73      0.75      0.73       108\n",
      "\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "#OneVsRest\n",
    "print(\"# Onevsrest\")\n",
    "get_classification_report(oneRest(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline 5: Using USE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elmo download started this may take some time.\n",
      "Approximate size to download 334.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "inputCol = \"translatedtext\"\n",
    "outputCol = \"Category1(Mandatory)\"\n",
    "pipeline = get_pipeline2(2,inputCol,outputCol)\n",
    "processed_df = pipeline.fit(df).transform(df)\n",
    "trainingData,testData = train_test_split(processed_df)\n",
    "trainingData,testData = process_train_test_data(trainingData,testData,\"features\")\n",
    "bins = len(df.select(outputCol).distinct().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Logistic Regression\n",
      "\n",
      "MulticlassEvaluator score:  1.0000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.91      0.86        23\n",
      "         1.0       0.72      0.87      0.79        15\n",
      "         2.0       0.29      0.82      0.43        11\n",
      "         3.0       0.83      0.71      0.77         7\n",
      "         4.0       1.00      0.78      0.88         9\n",
      "         5.0       0.50      0.75      0.60         4\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "         7.0       1.00      0.33      0.50         3\n",
      "         8.0       0.00      0.00      0.00         2\n",
      "         9.0       0.60      0.75      0.67         4\n",
      "        10.0       1.00      0.25      0.40         4\n",
      "        11.0       1.00      1.00      1.00         5\n",
      "        12.0       0.00      0.00      0.00         3\n",
      "        13.0       0.00      0.00      0.00         4\n",
      "        14.0       0.00      0.00      0.00         1\n",
      "        15.0       0.00      0.00      0.00         2\n",
      "        16.0       0.00      0.00      0.00         1\n",
      "        18.0       0.00      0.00      0.00         1\n",
      "        19.0       0.00      0.00      0.00         1\n",
      "        21.0       0.00      0.00      0.00         1\n",
      "        22.0       0.00      0.00      0.00         2\n",
      "        26.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.63       108\n",
      "   macro avg       0.35      0.33      0.31       108\n",
      "weighted avg       0.59      0.63      0.58       108\n",
      "\n",
      "0.6296296296296297\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "print(\"# Logistic Regression\\n\")\n",
    "get_classification_report(logistic_regression(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Random Forest\n",
      "MulticlassEvaluator score:  1.0000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      1.00      0.74        23\n",
      "         1.0       0.59      0.87      0.70        15\n",
      "         2.0       0.25      0.55      0.34        11\n",
      "         3.0       0.44      0.57      0.50         7\n",
      "         4.0       1.00      0.67      0.80         9\n",
      "         5.0       1.00      0.50      0.67         4\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "         7.0       1.00      0.33      0.50         3\n",
      "         8.0       0.00      0.00      0.00         2\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.00      0.00      0.00         4\n",
      "        11.0       1.00      1.00      1.00         5\n",
      "        12.0       0.00      0.00      0.00         3\n",
      "        13.0       0.00      0.00      0.00         4\n",
      "        14.0       0.00      0.00      0.00         1\n",
      "        15.0       0.00      0.00      0.00         2\n",
      "        16.0       0.00      0.00      0.00         1\n",
      "        18.0       0.00      0.00      0.00         1\n",
      "        19.0       0.00      0.00      0.00         1\n",
      "        21.0       0.00      0.00      0.00         1\n",
      "        22.0       0.00      0.00      0.00         2\n",
      "        26.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.56       108\n",
      "   macro avg       0.27      0.25      0.24       108\n",
      "weighted avg       0.46      0.56      0.47       108\n",
      "\n",
      "0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "print(\"# Random Forest\")\n",
    "get_classification_report(random_forest_classifier(trainingData,testData,\"features\",\"label\",bins),\"features\",\"label\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Onevsrest\n",
      "MulticlassEvaluator score:  1.0000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.91      0.93        23\n",
      "         1.0       0.78      0.93      0.85        15\n",
      "         2.0       0.62      0.73      0.67        11\n",
      "         3.0       0.67      0.57      0.62         7\n",
      "         4.0       0.89      0.89      0.89         9\n",
      "         5.0       0.75      0.75      0.75         4\n",
      "         6.0       0.17      0.25      0.20         4\n",
      "         7.0       1.00      0.33      0.50         3\n",
      "         8.0       0.50      1.00      0.67         2\n",
      "         9.0       1.00      1.00      1.00         4\n",
      "        10.0       0.33      0.25      0.29         4\n",
      "        11.0       1.00      1.00      1.00         5\n",
      "        12.0       0.67      0.67      0.67         3\n",
      "        13.0       0.00      0.00      0.00         4\n",
      "        14.0       0.50      1.00      0.67         1\n",
      "        15.0       1.00      1.00      1.00         2\n",
      "        16.0       1.00      1.00      1.00         1\n",
      "        18.0       0.50      1.00      0.67         1\n",
      "        19.0       1.00      1.00      1.00         1\n",
      "        21.0       0.00      0.00      0.00         1\n",
      "        22.0       0.00      0.00      0.00         2\n",
      "        26.0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.75       108\n",
      "   macro avg       0.65      0.69      0.65       108\n",
      "weighted avg       0.73      0.75      0.73       108\n",
      "\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "#OneVsRest\n",
    "print(\"# Onevsrest\")\n",
    "get_classification_report(oneRest(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "print(\"# Logistic Regression\\n\")\n",
    "get_classification_report(logistic_regression(trainingData,testData),\"features\",\"label\")\n",
    "#Random Forest\n",
    "print(\"# Random Forest\")\n",
    "get_classification_report(random_forest_classifier(trainingData,testData,\"features\",\"label\",bins),\"features\",\"label\")    \n",
    "\n",
    "#Naive Bayes\n",
    "print(\"# Naive Bayes\")\n",
    "get_classification_report(naive_bayes(trainingData,testData),\"features\",\"label\")\n",
    "#OneVsRest\n",
    "print(\"# Onevsrest\")\n",
    "get_classification_report(oneRest(trainingData,testData),\"features\",\"label\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
