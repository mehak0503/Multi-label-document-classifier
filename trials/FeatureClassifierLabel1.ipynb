{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "spark = sparknlp.start() # for GPU training >> sparknlp.start(gpu = True) # for Spark 2.3 =>> sparknlp.start(spark23 = True)\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "from allComponents import Components\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.classification import LogisticRegression,LinearSVC\n",
    "from pyspark.ml.classification import RandomForestClassifier, OneVsRest\n",
    "from pyspark.ml.classification import NaiveBayes,MultilayerPerceptronClassifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.sql.functions import *\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "sc =SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataframe = pd.read_csv('../Document Categorisation.csv',engine=\"python\")\n",
    "dataframe['path'] = [i.split('\\\\') for i in dataframe['Location']]\n",
    "dataframe.to_csv('../PathCategorisation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Category 1 (Mandatory)</th>\n",
       "      <th>Category 2 (Optional)</th>\n",
       "      <th>Category 3 (Optional)</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Complaints policy.docx</td>\n",
       "      <td>C:\\Users\\classifier-admin\\Desktop\\Data\\ACQSC (...</td>\n",
       "      <td>Policy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[C:, Users, classifier-admin, Desktop, Data, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abbeyhouseagedcare2610-6.pdf</td>\n",
       "      <td>C:\\Users\\classifier-admin\\Desktop\\Data\\AACQA (...</td>\n",
       "      <td>Audit</td>\n",
       "      <td>Abbey House Aged Care</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[C:, Users, classifier-admin, Desktop, Data, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aacqa_annual_report_2017-18.pdf</td>\n",
       "      <td>C:\\Users\\classifier-admin\\Desktop\\Data\\AACQA (...</td>\n",
       "      <td>Annual Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[C:, Users, classifier-admin, Desktop, Data, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aacqa_annual_report_accessibility_17_november_...</td>\n",
       "      <td>C:\\Users\\classifier-admin\\Desktop\\Data\\AACQA (...</td>\n",
       "      <td>Annual Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[C:, Users, classifier-admin, Desktop, Data, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aacqa_table_a_executive_remuneration.docx</td>\n",
       "      <td>C:\\Users\\classifier-admin\\Desktop\\Data\\AACQA (...</td>\n",
       "      <td>Annual Report</td>\n",
       "      <td>Executive Remuneration</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[C:, Users, classifier-admin, Desktop, Data, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>NFP-Principles-and-Guidance-131015.pdf</td>\n",
       "      <td>C:\\Users\\classifier-admin\\Desktop\\Data\\Handbooks</td>\n",
       "      <td>Handbook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[C:, Users, classifier-admin, Desktop, Data, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>Best in Care Australia - Actions.pdf</td>\n",
       "      <td>C:\\Users\\classifier-admin\\Desktop\\Data</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[C:, Users, classifier-admin, Desktop, Data]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>Bupa Seaforth - Actions.pdf</td>\n",
       "      <td>C:\\Users\\classifier-admin\\Desktop\\Data</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[C:, Users, classifier-admin, Desktop, Data]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>PCA018_Guiding-Principles-for-PC-Aged-Care_W03...</td>\n",
       "      <td>C:\\Users\\classifier-admin\\Desktop\\Data</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[C:, Users, classifier-admin, Desktop, Data]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>Sector performance_External report definitions...</td>\n",
       "      <td>C:\\Users\\classifier-admin\\Desktop\\Data</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[C:, Users, classifier-admin, Desktop, Data]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Document Name  \\\n",
       "0                               Complaints policy.docx   \n",
       "1                         abbeyhouseagedcare2610-6.pdf   \n",
       "2                      aacqa_annual_report_2017-18.pdf   \n",
       "3    aacqa_annual_report_accessibility_17_november_...   \n",
       "4            aacqa_table_a_executive_remuneration.docx   \n",
       "..                                                 ...   \n",
       "562             NFP-Principles-and-Guidance-131015.pdf   \n",
       "563               Best in Care Australia - Actions.pdf   \n",
       "564                        Bupa Seaforth - Actions.pdf   \n",
       "565  PCA018_Guiding-Principles-for-PC-Aged-Care_W03...   \n",
       "566  Sector performance_External report definitions...   \n",
       "\n",
       "                                              Location Category 1 (Mandatory)  \\\n",
       "0    C:\\Users\\classifier-admin\\Desktop\\Data\\ACQSC (...                 Policy   \n",
       "1    C:\\Users\\classifier-admin\\Desktop\\Data\\AACQA (...                  Audit   \n",
       "2    C:\\Users\\classifier-admin\\Desktop\\Data\\AACQA (...          Annual Report   \n",
       "3    C:\\Users\\classifier-admin\\Desktop\\Data\\AACQA (...          Annual Report   \n",
       "4    C:\\Users\\classifier-admin\\Desktop\\Data\\AACQA (...          Annual Report   \n",
       "..                                                 ...                    ...   \n",
       "562   C:\\Users\\classifier-admin\\Desktop\\Data\\Handbooks               Handbook   \n",
       "563             C:\\Users\\classifier-admin\\Desktop\\Data                  Other   \n",
       "564             C:\\Users\\classifier-admin\\Desktop\\Data                  Other   \n",
       "565             C:\\Users\\classifier-admin\\Desktop\\Data                  Other   \n",
       "566             C:\\Users\\classifier-admin\\Desktop\\Data                  Other   \n",
       "\n",
       "      Category 2 (Optional) Category 3 (Optional)  \\\n",
       "0                       NaN                   NaN   \n",
       "1     Abbey House Aged Care                   NaN   \n",
       "2                       NaN                   NaN   \n",
       "3                       NaN                   NaN   \n",
       "4    Executive Remuneration                   NaN   \n",
       "..                      ...                   ...   \n",
       "562                     NaN                   NaN   \n",
       "563                     NaN                   NaN   \n",
       "564                     NaN                   NaN   \n",
       "565                     NaN                   NaN   \n",
       "566                     NaN                   NaN   \n",
       "\n",
       "                                                  path  \n",
       "0    [C:, Users, classifier-admin, Desktop, Data, A...  \n",
       "1    [C:, Users, classifier-admin, Desktop, Data, A...  \n",
       "2    [C:, Users, classifier-admin, Desktop, Data, A...  \n",
       "3    [C:, Users, classifier-admin, Desktop, Data, A...  \n",
       "4    [C:, Users, classifier-admin, Desktop, Data, A...  \n",
       "..                                                 ...  \n",
       "562  [C:, Users, classifier-admin, Desktop, Data, H...  \n",
       "563       [C:, Users, classifier-admin, Desktop, Data]  \n",
       "564       [C:, Users, classifier-admin, Desktop, Data]  \n",
       "565       [C:, Users, classifier-admin, Desktop, Data]  \n",
       "566       [C:, Users, classifier-admin, Desktop, Data]  \n",
       "\n",
       "[567 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    data = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('../dataset.csv')\n",
    "    data1 = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('../PathCategorisation.csv')\n",
    "    df = data.join(data1, (data['filename'] == data1['Document Name']))\n",
    "    oldColumns = ['filename','filepath','filetype','filesize','filetext','translatedtext','Document Name','Location','Category 1 (Mandatory)','Category 2 (Optional)','Category 3 (Optional)']\n",
    "    newColumns = ['filename','filepath','filetype','filesize','filetext','translatedtext','DocumentName','Location','Category1(Mandatory)','Category2(Optional)','Category3(Optional)']\n",
    "    df = reduce(lambda data, idx: data.withColumnRenamed(oldColumns[idx], newColumns[idx]), range(len(oldColumns)), df)\n",
    "    drop_list = ['filename', 'filepath','filetext','Category3(Optional)']\n",
    "    result = df.select([column for column in df.columns if column not in drop_list])\n",
    "    #result.show(5)\n",
    "    return result\n",
    "\n",
    "df = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------------------+---+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
      "|filetype|filesize|      translatedtext|_c0|        DocumentName|            Location|Category1(Mandatory)|Category2(Optional)|                path|\n",
      "+--------+--------+--------------------+---+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
      "|     pdf|  110537|Sector performanc...|566|Sector performanc...|C:\\Users\\classifi...|               Other|               null|['C:', 'Users', '...|\n",
      "|     pdf|   61331|Bupa Seaforth   T...|564|Bupa Seaforth - A...|C:\\Users\\classifi...|               Other|               null|['C:', 'Users', '...|\n",
      "|     pdf|  123920|Best in Care Aust...|563|Best in Care Aust...|C:\\Users\\classifi...|               Other|               null|['C:', 'Users', '...|\n",
      "|     pdf|  626923|Principles for Pa...|565|PCA018_Guiding-Pr...|C:\\Users\\classifi...|               Other|               null|['C:', 'Users', '...|\n",
      "|     pdf|  239340|Page 1 of 9RB 202...|475|rb_2020-10_qualit...|C:\\Users\\classifi...| Regulatory Bulletin|               null|['C:', 'Users', '...|\n",
      "+--------+--------+--------------------+---+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------------------+---+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
      "|filetype|filesize|      translatedtext|_c0|        DocumentName|            Location|Category1(Mandatory)|Category2(Optional)|                path|\n",
      "+--------+--------+--------------------+---+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
      "|     pdf|  110537|Sector performanc...|566|Sector performanc...|C:\\Users\\classifi...|               Other|       NotSpecified|['C:', 'Users', '...|\n",
      "+--------+--------+--------------------+---+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.na.fill(\"NotSpecified\")#Fill empty\n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataframe):\n",
    "    (trainingData, testData) = dataframe.randomSplit([0.8, 0.2], seed = 100)\n",
    "    return trainingData, testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_test_data(trainingData,testData,outputCol):\n",
    "    @udf(\"long\")\n",
    "    def num_nonzeros(v):\n",
    "        return v.numNonzeros()\n",
    "    testData = testData.where(num_nonzeros(outputCol) != 0)\n",
    "    trainingData = trainingData.where(num_nonzeros(outputCol) != 0)\n",
    "    return trainingData,testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(dataframe,inputCol,outputCol):\n",
    "    print(dataframe.show(1))\n",
    "    evaluator = MulticlassClassificationEvaluator(predictionCol=outputCol)\n",
    "    print(\"MulticlassEvaluator score: \",evaluator.evaluate(dataframe))\n",
    "    df = dataframe.select(inputCol,outputCol,\"prediction\").toPandas()\n",
    "    print(classification_report(df.label, df.prediction))\n",
    "    print(accuracy_score(df.label, df.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(trainingData,testData):\n",
    "    lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0)\n",
    "    return lr.fit(trainingData).transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def oneRest(trainingData,testData):\n",
    "    lr = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True)\n",
    "    ovr = OneVsRest(classifier=lr)\n",
    "    model = ovr.fit(trainingData)\n",
    "    return model\n",
    "    #model.save(\"~/featureLabel1.model\")\n",
    "    #return ovr.fit(trainingData).transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_classifier(trainingData,testData,inputCol,outputCol,bins):\n",
    "    rf = RandomForestClassifier(labelCol=outputCol, \\\n",
    "                            featuresCol=inputCol, \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = bins)\n",
    "\n",
    "    # Train model with Training Data\n",
    "    return rf.fit(trainingData).transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(trainingData,testData):\n",
    "    nb = NaiveBayes(smoothing=1)\n",
    "    return nb.fit(trainingData).transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline1(choice,outCol,*inputCol):\n",
    "    c = Components()\n",
    "    allStages = [c.getDocumentAssembler(inputCol[0],\"document\"),c.getTokenizer(\"document\",\"tokens\"),\\\n",
    "                  c.getNormalizer(\"tokens\",\"normalized\"),\\\n",
    "                c.getFinisher(\"normalized\",\"finished\")]\n",
    "    if choice==0:#CountVectorizer\n",
    "        allStages.extend([c.getCountVectorizer(\"finished\",\"locFeature\"),c.getStringIndexer(inputCol[1],\"typeFeature\"),\\\n",
    "                          c.getVectorAssembler([\"locFeature\",\"typeFeature\",inputCol[2]],\"features\"),\\\n",
    "                          c.getStringIndexer(outCol,\"label\")])\n",
    "        return Pipeline(stages=allStages)\n",
    "    elif choice==1:#Tf-idf\n",
    "        allStages.extend([c.getTf(\"finished\",\"tf\"),c.getIdf(\"tf\",\"locFeature\"),\\\n",
    "                          c.getStringIndexer(inputCol[1],\"typeFeature\"),\\\n",
    "                          c.getVectorAssembler([\"locFeature\",\"typeFeature\",inputCol[2]],\"features\"),\\\n",
    "                          c.getStringIndexer(outCol,\"label\")])\n",
    "        return Pipeline(stages=allStages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Label 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline 1: Using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputCol = \"path\"\n",
    "outputCol = \"Category1(Mandatory)\"\n",
    "pipeline = get_pipeline1(0,outputCol,inputCol,\"filetype\",\"filesize\")\n",
    "processed_df = pipeline.fit(df).transform(df)\n",
    "trainingData,testData = train_test_split(processed_df)\n",
    "bins = len(df.select(outputCol).distinct().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ['Audit',\n",
       "  'Draft Guidance Material',\n",
       "  'Aged Care Quality Standards',\n",
       "  'Charter of Aged Care Rights',\n",
       "  'Dept Health',\n",
       "  'COVID-19',\n",
       "  'Handbook',\n",
       "  'Standards Guidance Reference Group',\n",
       "  'Annual Report',\n",
       "  'Regulatory Bulletin',\n",
       "  'Notice of Collection',\n",
       "  'Self Assessment',\n",
       "  'Accreditation',\n",
       "  'Other',\n",
       "  'Corporate Plan',\n",
       "  'Newsletter',\n",
       "  'Key Changes for Providers',\n",
       "  'Statements ',\n",
       "  'Memorandum of Understanding',\n",
       "  'Policy',\n",
       "  'Sector Performance',\n",
       "  'Human Resources',\n",
       "  'Consumer Experience',\n",
       "  'Clinical Care Standard',\n",
       "  'Report',\n",
       "  'Advanced Care Planning',\n",
       "  'NOUS Report']}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{c.name: c.metadata[\"ml_attr\"][\"vals\"] for c in processed_df.schema.fields if c.name.endswith(\"label\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Random Forest\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      1.00      0.81        22\n",
      "         1.0       1.00      1.00      1.00        14\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "         3.0       1.00      1.00      1.00        11\n",
      "         4.0       1.00      1.00      1.00         7\n",
      "         5.0       0.33      1.00      0.50         7\n",
      "         6.0       0.40      0.25      0.31         8\n",
      "         7.0       1.00      1.00      1.00         1\n",
      "         8.0       1.00      0.50      0.67         4\n",
      "         9.0       1.00      1.00      1.00         6\n",
      "        10.0       1.00      1.00      1.00         3\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "        12.0       0.00      0.00      0.00         5\n",
      "        13.0       0.00      0.00      0.00         3\n",
      "        14.0       0.00      0.00      0.00         2\n",
      "        16.0       0.00      0.00      0.00         2\n",
      "        20.0       0.00      0.00      0.00         1\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.75       109\n",
      "   macro avg       0.52      0.54      0.52       109\n",
      "weighted avg       0.68      0.75      0.69       109\n",
      "\n",
      "0.7522935779816514\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "print(\"# Random Forest\")\n",
    "get_classification_report(random_forest_classifier(trainingData,testData,\"features\",\"label\",bins),\"features\",\"label\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2.0: 'Storyboard',\n",
       " 1.0: 'Report',\n",
       " 0.0: 'Abel Tasman Village',\n",
       " 20.0: 'NotSpecified',\n",
       " 4.0: 'Polish',\n",
       " 12.0: 'Fact sheet',\n",
       " 10.0: 'Turkish',\n",
       " 16.0: 'Fact sheet',\n",
       " 7.0: 'Communique',\n",
       " 14.0: 'NotSpecified',\n",
       " 3.0: 'A Little Yarn',\n",
       " 6.0: 'NotSpecified',\n",
       " 5.0: 'Storyboard',\n",
       " 22.0: 'NotSpecified',\n",
       " 8.0: 'NotSpecified',\n",
       " 11.0: 'Feedback',\n",
       " 13.0: 'NotSpecified',\n",
       " 9.0: 'NotSpecified'}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Naive Bayes\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95        22\n",
      "         1.0       0.92      0.86      0.89        14\n",
      "         2.0       0.75      0.86      0.80         7\n",
      "         3.0       1.00      0.73      0.84        11\n",
      "         4.0       0.44      1.00      0.61         7\n",
      "         5.0       0.38      0.43      0.40         7\n",
      "         6.0       0.25      0.12      0.17         8\n",
      "         7.0       0.25      1.00      0.40         1\n",
      "         8.0       0.43      0.75      0.55         4\n",
      "         9.0       1.00      1.00      1.00         6\n",
      "        10.0       0.43      1.00      0.60         3\n",
      "        11.0       1.00      0.80      0.89         5\n",
      "        12.0       0.00      0.00      0.00         5\n",
      "        13.0       0.00      0.00      0.00         3\n",
      "        14.0       1.00      0.50      0.67         2\n",
      "        16.0       1.00      0.50      0.67         2\n",
      "        20.0       0.00      0.00      0.00         1\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.71       109\n",
      "   macro avg       0.54      0.58      0.52       109\n",
      "weighted avg       0.70      0.71      0.68       109\n",
      "\n",
      "0.7064220183486238\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "print(\"# Naive Bayes\")\n",
    "get_classification_report(naive_bayes(trainingData,testData),\"features\",\"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Onevsrest\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        22\n",
      "         1.0       1.00      1.00      1.00        14\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "         3.0       1.00      1.00      1.00        11\n",
      "         4.0       1.00      1.00      1.00         7\n",
      "         5.0       0.78      1.00      0.88         7\n",
      "         6.0       1.00      0.75      0.86         8\n",
      "         7.0       1.00      1.00      1.00         1\n",
      "         8.0       1.00      1.00      1.00         4\n",
      "         9.0       1.00      1.00      1.00         6\n",
      "        10.0       1.00      1.00      1.00         3\n",
      "        11.0       1.00      1.00      1.00         5\n",
      "        12.0       1.00      1.00      1.00         5\n",
      "        13.0       1.00      1.00      1.00         3\n",
      "        14.0       1.00      1.00      1.00         2\n",
      "        16.0       1.00      1.00      1.00         2\n",
      "        20.0       1.00      1.00      1.00         1\n",
      "        22.0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.98       109\n",
      "   macro avg       0.99      0.99      0.99       109\n",
      "weighted avg       0.99      0.98      0.98       109\n",
      "\n",
      "0.981651376146789\n"
     ]
    }
   ],
   "source": [
    "#OneVsRest\n",
    "print(\"# Onevsrest\")\n",
    "get_classification_report(oneRest(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline 2: Using Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputCol = \"path\"\n",
    "outputCol = \"Category1(Mandatory)\"\n",
    "pipeline = get_pipeline1(1,outputCol,inputCol,\"filetype\",\"filesize\")\n",
    "processed_df = pipeline.fit(df).transform(df)\n",
    "trainingData,testData = train_test_split(processed_df)\n",
    "bins = len(df.select(outputCol).distinct().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Logistic Regression\n",
      "\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92        22\n",
      "         1.0       1.00      1.00      1.00        14\n",
      "         2.0       0.88      1.00      0.93         7\n",
      "         3.0       1.00      1.00      1.00        11\n",
      "         4.0       1.00      1.00      1.00         7\n",
      "         5.0       0.78      1.00      0.88         7\n",
      "         6.0       1.00      0.62      0.77         8\n",
      "         7.0       1.00      1.00      1.00         1\n",
      "         8.0       1.00      1.00      1.00         4\n",
      "         9.0       1.00      1.00      1.00         6\n",
      "        10.0       1.00      1.00      1.00         3\n",
      "        11.0       1.00      1.00      1.00         5\n",
      "        12.0       1.00      1.00      1.00         5\n",
      "        13.0       0.00      0.00      0.00         3\n",
      "        14.0       1.00      1.00      1.00         2\n",
      "        16.0       1.00      1.00      1.00         2\n",
      "        20.0       1.00      1.00      1.00         1\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.94       109\n",
      "   macro avg       0.86      0.87      0.86       109\n",
      "weighted avg       0.91      0.94      0.92       109\n",
      "\n",
      "0.9357798165137615\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "print(\"# Logistic Regression\\n\")\n",
    "get_classification_report(logistic_regression(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Random Forest\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      1.00      0.40        22\n",
      "         1.0       1.00      0.93      0.96        14\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "         3.0       0.00      0.00      0.00        11\n",
      "         4.0       0.00      0.00      0.00         7\n",
      "         5.0       0.00      0.00      0.00         7\n",
      "         6.0       0.00      0.00      0.00         8\n",
      "         7.0       0.00      0.00      0.00         1\n",
      "         8.0       0.00      0.00      0.00         4\n",
      "         9.0       0.00      0.00      0.00         6\n",
      "        10.0       0.00      0.00      0.00         3\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "        12.0       0.00      0.00      0.00         5\n",
      "        13.0       0.00      0.00      0.00         3\n",
      "        14.0       0.00      0.00      0.00         2\n",
      "        16.0       0.00      0.00      0.00         2\n",
      "        20.0       0.00      0.00      0.00         1\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.39       109\n",
      "   macro avg       0.12      0.16      0.13       109\n",
      "weighted avg       0.24      0.39      0.27       109\n",
      "\n",
      "0.3853211009174312\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "print(\"# Random Forest\")\n",
    "get_classification_report(random_forest_classifier(trainingData,testData,\"features\",\"label\",bins),\"features\",\"label\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Naive Bayes\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.36      0.50        22\n",
      "         1.0       1.00      0.21      0.35        14\n",
      "         2.0       0.21      0.43      0.29         7\n",
      "         3.0       1.00      0.27      0.43        11\n",
      "         4.0       0.00      0.00      0.00         7\n",
      "         5.0       0.00      0.00      0.00         7\n",
      "         6.0       0.10      1.00      0.18         8\n",
      "         7.0       0.00      0.00      0.00         1\n",
      "         8.0       0.00      0.00      0.00         4\n",
      "         9.0       0.00      0.00      0.00         6\n",
      "        10.0       0.00      0.00      0.00         3\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "        12.0       0.00      0.00      0.00         5\n",
      "        13.0       0.00      0.00      0.00         3\n",
      "        14.0       0.00      0.00      0.00         2\n",
      "        16.0       0.00      0.00      0.00         2\n",
      "        20.0       0.00      0.00      0.00         1\n",
      "        22.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.23       109\n",
      "   macro avg       0.17      0.13      0.10       109\n",
      "weighted avg       0.41      0.23      0.22       109\n",
      "\n",
      "0.22935779816513763\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "print(\"# Naive Bayes\")\n",
    "get_classification_report(naive_bayes(trainingData,testData),\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Onevsrest\n",
      "MulticlassEvaluator score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        22\n",
      "         1.0       1.00      1.00      1.00        14\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "         3.0       1.00      1.00      1.00        11\n",
      "         4.0       1.00      1.00      1.00         7\n",
      "         5.0       0.78      1.00      0.88         7\n",
      "         6.0       1.00      0.75      0.86         8\n",
      "         7.0       1.00      1.00      1.00         1\n",
      "         8.0       1.00      1.00      1.00         4\n",
      "         9.0       1.00      1.00      1.00         6\n",
      "        10.0       1.00      1.00      1.00         3\n",
      "        11.0       1.00      1.00      1.00         5\n",
      "        12.0       1.00      1.00      1.00         5\n",
      "        13.0       1.00      1.00      1.00         3\n",
      "        14.0       1.00      1.00      1.00         2\n",
      "        16.0       1.00      1.00      1.00         2\n",
      "        20.0       1.00      1.00      1.00         1\n",
      "        22.0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.98       109\n",
      "   macro avg       0.99      0.99      0.99       109\n",
      "weighted avg       0.99      0.98      0.98       109\n",
      "\n",
      "0.981651376146789\n"
     ]
    }
   ],
   "source": [
    "#OneVsRest\n",
    "print(\"# Onevsrest\")\n",
    "get_classification_report(oneRest(trainingData,testData),\"features\",\"label\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
